---
title: "Hands-on Ex04-2"
author: "Cathy C"
date-modified: "last-modified" 
execute:
  echo: true 
  eval: true 
  warning: false 
  freeze: true  
---

# Visual Statistical Analysis

## [4-2.1]{style="color:skyblue"} Learning Outcome

In this hands-on exercise, we will gain hands-on experience on using:

-   **ggstatsplot** package to create visual graphics with rich statistical information.
-   **performance** package to visualise model diagnostics.
-   **parameters** package to visualise model parameters.

## [4-2.2]{style="color:skyblue"} Visual Statistical Analysis with **ggstatsplot**

[**ggstatsplot**](https://indrajeetpatil.github.io/ggstatsplot/index.html) ![](images/ggstatsplot.png){width="40"}is an extension of [**ggplot2**](https://ggplot2.tidyverse.org/) package for creating graphics with details from statistical tests included in the information-rich plots themselves.

``` r
- to provide alternative statistical inference methods by default.
- to follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. 
For example, here are results from a robust t-test:
```

![](images/stats_reporting_format.png)

## [4-2.3]{style="color:skyblue"} Getting started

### [4-2.3.1]{style="color:skyblue"} Installing and launching R packages

In this exercise, g**gstatsplot** and **tidyverse** will be used.

```{r}
pacman::p_load(ggstatsplot, tidyverse)
```

### [4-2.3.2]{style="color:skyblue"} Importing data

::: callout-note
## DIY

Import Exam-csv data by using appropriate tidyverse package.

```{r}
exam <- read_csv("data/Exam_data.csv")
```
:::

### [4-2.3.3]{style="color:skyblue"} One-sample test: *`gghistostats()`* method

In the code chunk below, [*`gghistostats()`*](https://indrajeetpatil.github.io/ggstatsplot/reference/gghistostats.html) is used to build an visual of one-sample test on English scores.

```{r}
set.seed(1234)

gghistostats(
  data = exam,
  x = ENGLISH,
  type = "bayes",
  test.value = 60,
  xlab = "English scores"
)
```

Default information:

statistical details / Bayes Factor / sample sizes / distribution summary

### [4-2.3.4]{style="color:skyblue"} Unpacking the Bayes Factor

-   A Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favour of one theory among two competing theories.

-   That's because the Bayes factor gives us a way to evaluate the data in favour of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favour of a given hypothesis.

-   When we are comparing two hypotheses, ***H1*** (the alternate hypothesis) and ***H0*** (the null hypothesis), the Bayes factor is often written as **B10**. It can be defined mathematically as:

    $$
    \frac{likelihood-of-data-given-H_1}{likelihood-of-data-given-H_0} = \frac{P(D|H_1)}{P(D/H_0)}
    $$

-   The [**Schwarz criterion**](https://www.statisticshowto.com/bayesian-information-criterion/) is one of the easiest ways to calculate rough estimation of the Bayes factor.

### [4-2.3.5]{style="color:skyblue"} How to interpret Bayes Factor

A Bayes Factor can be any positive number.

One of the most common interpretation is this one - first proposed by Harold Jeffereys (1961) and slightly modified by [Lee and Wagemakers](https://www-tandfonline-com.libproxy.smu.edu.sg/doi/pdf/10.1080/00031305.1999.10474443?needAccess=true) in 2013.

| IF B10 IS... | THEN YOU HAVE               |
|--------------|-----------------------------|
| \>100        | Extreme evidence for H1     |
| 30 - 100     | Very strong evidence for H1 |
| 10 - 30      | Strong evidence for H1      |
| 3 - 10       | Moderate evidence for H1    |
| 1 - 3        | Anecdotal evidence for H1   |
| 1            | No evidence                 |
| 1/3 - 1      | Anecdotal evidence for H1   |
| 1/3 - 1/10   | Moderate evidence for H1    |
| 1/10 - 1/30  | Strong evidence for H1      |
| 1/30 - 1/100 | Very Strong evidence for H1 |
| \<1/100      | Extreme evidence for H1     |

: Bayes Factor {.striped .hover}

### [4-2.3.6]{style="color:skyblue"} Two-sample mean test: *`ggbetweenstats()`*

In the code chunk below, [ggbetweenstats()](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbetweenstats.html) is used to build a visual for two-sample mean test of Maths scores by gender.

```{r}
ggbetweenstats(
  data = exam,
  x = GENDER,
  y = MATHS,
  type = "np",
  message = FALSE
)

```

Default information: statistical details / Bayes factor / samples sizes / distribution summary

### [4-2.3.7]{style="color:skyblue"} Oneway ANOVA Test: *`ggbetweentats()`* method

In the code chunk below, [ggbetweenstats()](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbetweenstats.html) is used to build a visual for One-way ANOVA test on English scores by race.

```{r}
ggbetweenstats(
  data = exam,
  x = RACE,
  y = ENGLISH,
  type = "p",
  mean.ci = TRUE,
  pariwise.comparisons = TRUE,
  pairwise.display = "s",
  p.adjust.methods = "fdr",
  message = FALSE
)
```

-   "na" -\> only non-significant
-   "s" -\> only significant
-   "all" -\> everything

#### [4-2.3.7.1]{style="color:skyblue"} *`ggbetweentats()`* - Summary of tests

Following (between-subjects) tests are carried out for each type of analyses.

| TYPE | NO. OF GROUPS | TEST |
|----|----|----|
| Parametric | \>2 | Fisher's or Welch's one-way ANOVA |
| Non-Parametric | \>2 | Kruskal-Wallis one-way ANOVA |
| Robust | \>2 | Heteroscedastic one-way ANOVA for trimmed means |
| Bayes Factor | \>2 | Fisher's ANOVA |
| Parametric | 2 | Student's or Welch's *t*-test |
| Non-Parametric | 2 | Mann-Whitney *U* test |
| Robust | 2 | Yuen's test for trimmed means |
| Bayes Factor | 2 | Student's *t*-test |

### [4-2.3.8]{style="color:skyblue"} Significant test of correlation: *`ggscatterstats()`*

In the code chunk below,

### [4-2.3.9]{style="color:skyblue"} Significant test of association (dependence): *`ggbarstats()`*

## [4-2.4]{style="color:skyblue"} Visualsing Models

## [4-2.5]{style="color:skyblue"} Getting started

## [4-2.6]{style="color:skyblue"} Installing and loading the required libraries

### [4-2.6.1]{style="color:skyblue"} Importing Excel file: readxl methods

### [4-2.6.2]{style="color:skyblue"} Multiple regression model using `lm()`

### [4-2.6.3]{style="color:skyblue"} Model diagnostic: checking for multicolinearity

### [4-2.6.4]{style="color:skyblue"} Model diagnostic: checking normality assumption

### [4-2.6.5]{style="color:skyblue"} Model diagnostic: check model for homogeneity of variances

### [4-2.6.6]{style="color:skyblue"} Model diagnostic: complete check

### [4-2.6.7]{style="color:skyblue"} Visualising regression parameters: see methods

### [4-2.6.8]{style="color:skyblue"} Visualising regression parameters: *`ggcoefstats()`* methods

:::
